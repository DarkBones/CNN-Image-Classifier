{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Image Preprocessing\n",
    "\n",
    "## Preprocessing data\n",
    "\n",
    "In this notebook, I have documented how the data for the CNN Picture Categorizer is preprocessed.\n",
    "\n",
    "The functions and parameters described in this document all belong to the **ImagePreprocessor** class in *image_preprocessor.py*.\n",
    "\n",
    "The Image Preprocessor is a class with the following important parameters:\n",
    "- **root_dir *(string)*** *the root directory where the images are stored*\n",
    "- **originals_dir *(string)*** *where the images of the original dataset are stored*\n",
    "- **training_dir *(string)*** *where the training images are stored*\n",
    "- **validation_dir *(string)*** *where the validation images are stored*\n",
    "- **test_dir *(string)*** *where the test images are stored*\n",
    "- **target_imagesize *(tuple)*** *a tuple describing the final size of the images*\n",
    "- **test_size *(float)*** *the percentage of images the test set contains*\n",
    "- **validation_size *(float)*** *the percentage of all images the validation set contains*\n",
    "- **training_count *(integer)*** *how many images there are in the training set*\n",
    "- **validation_count *(integer)*** *how many images there are in the validation set*\n",
    "- **test_count *(integer)*** *how many images there are in the test set*\n",
    "- **categories *(string array)*** *an array with the names of all the categories (classes)*\n",
    "\n",
    "The Image Processor performs the following *public* functions:\n",
    "- **initialize** *splits the original dataset into training, validation and test sets and records their respective sizes*\n",
    "- **file_to_tensor(*file*)** *takes a single image location and returns its matrix representation*\n",
    "- **files_to_tensor(*files*)** *takes a list of files and returns their matrix representations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import re\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Initialize parameters\n",
    "\n",
    "Set the default values for the parameters for the functions to refer to later. When initializing the ImagePreprocessor class, these can be changed before calling the *initialize()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the default values for the parameters\n",
    "root_dir = os.path.join('..', 'application', 'images')\n",
    "originals_dir = os.path.join(root_dir, 'original')\n",
    "training_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'validation')\n",
    "test_dir = os.path.join(root_dir, 'test')\n",
    "\n",
    "target_imagesize = (256, 256)\n",
    "\n",
    "# the sizes of the test and validation sets as compared to the total amount of images\n",
    "test_size = 0.2\n",
    "validation_size = 0.2\n",
    "\n",
    "clear_existing_data = False # if true, data in training, test and validation directories will be deleted before splitting the data in the originals directory\n",
    "\n",
    "random_seed = 7\n",
    "\n",
    "# the amount of images in the training, validation and test sets\n",
    "training_count = 0\n",
    "validation_count = 0\n",
    "test_count = 0\n",
    "\n",
    "# list of categories\n",
    "categories = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Split the dataset\n",
    "\n",
    "A model will be trained with the training set and validated with the validation set. Whenever the performance on the validation set improves, the weights of the model are saved (overwriting the previously best performing weights). Several models will be trained in this fashion.\n",
    "\n",
    "After all models have been trained, we choose the one that performs best on data it hasn't seen before; the test set.\n",
    "\n",
    "This is why, in order to train our model and to test how well the model is performing, the dataset must be split up randomly into training, validation and test sets.\n",
    "\n",
    "The __split_dataset function will go through the images in the original dataset and split them into training, validation and test sets according to the *test_size* and *validation_size* parameters set above.\n",
    "\n",
    "Both functions can only be called from inside the class, since the public *initialize()* function will call them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to remove all files in given directory\n",
    "def __empty_directory(path):\n",
    "    for file in os.listdir(path):\n",
    "        os.remove(os.path.join(path, file))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splits images in original directory into training, test and validation directories\n",
    "def __split_dataset():\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    size_count = 0\n",
    "    for category in os.listdir(originals_dir):\n",
    "        # make a new directory where they don't exist and empty existing directories\n",
    "        for p in [re.split(r'[\\\\/]', training_dir)[-1], re.split(r'[\\\\/]', val_dir)[-1], re.split(r'[\\\\/]', test_dir)[-1]]:\n",
    "            if not os.path.exists(os.path.join(root_dir, p, category)):\n",
    "                os.makedirs(os.path.join(root_dir, p, category))\n",
    "            if clear_existing_data == True:\n",
    "                __empty_directory(os.path.join(root_dir, p, category))\n",
    "            \n",
    "        # collect all the files in the originals directory\n",
    "        files = []\n",
    "        for file in os.listdir(os.path.join(originals_dir, category)):\n",
    "            files.append(file)\n",
    "        \n",
    "        # calculate the training, validation and test set sizes\n",
    "        test_count = round(len(files) * test_size)\n",
    "        validation_count = round(len(files) * val_size)\n",
    "        train_count = len(files) - test_count - validation_count\n",
    "        \n",
    "        # randomly shuffle the array of files\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        for i, file in enumerate(files):\n",
    "            location = None\n",
    "            if i < test_count:\n",
    "                location = test_dir\n",
    "            elif i < test_count + validation_count:\n",
    "                location = val_dir\n",
    "            else:\n",
    "                location = training_dir\n",
    "                \n",
    "            shutil.copyfile(os.path.join(originals_dir, category, file), os.path.join(location, category, file))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Getting additional class parameters\n",
    "\n",
    "The code that initialized the *ImagePreprocessor* class described in this document may need to know additional information with regards to how large each dataset is and what the names of the categories are.\n",
    "\n",
    "The *training_count*, *validation_count*, *test_count* and *categories* variables are not assigned any values by default. After the data has been split, we can count how many images are in each of the datasets and what categories are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns an array with the category names\n",
    "def __get_categories():        \n",
    "    return [item[len(originals_dir)+1:] for item in sorted(glob(os.path.join(originals_dir, \"*\")))]\n",
    "\n",
    "# returns the sizes of the training, validation and test sets\n",
    "def __get_dataset_sizes():\n",
    "    train_size = sum([len(files) for r, d, files in os.walk(training_dir)])\n",
    "    validation_size = sum([len(files) for r, d, files in os.walk(val_dir)])\n",
    "    test_size = sum([len(files) for r, d, files in os.walk(test_dir)])\n",
    "    \n",
    "    return train_size, validation_size, test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Initialize the class\n",
    "\n",
    "Now that all private functions are in place, we can call the public master function to call them in the correct order.\n",
    "\n",
    "The *initialize* function is the only function that needs to be called after initializing the ImagePreprocessor class. It will proceed to split the datasets and the class will store information about the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize(self):\n",
    "    __split_dataset()\n",
    "    \n",
    "    training_count, validation_count, test_count = __get_dataset_sizes()\n",
    "    categories = __get_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Convert images into tensors\n",
    "\n",
    "The code section below converts these images into tensors; matrices of numeric values representing how bright each pixel in the image is. The numeric values are then normalized so they are all within a range of between 0 and 1, rather than between 0 and 255.\n",
    "\n",
    "This normalization makes it easier for the model to train, as all pixels are now in the same range relative to the brightest pixel in each particular image. The brighest pixel in a dark image will still be of value 1, even though it may not have been 255 before the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes a list of image filepaths and returns a list of 4D tensors\n",
    "def file_to_tensor(self, file):\n",
    "    img = image.load_img(file, target_size=target_imagesize)\n",
    "    x = image.img_to_array(img)\n",
    "    x *= (1.0/x.max()) # set the range of the tensor values between 0 and 1\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def files_to_tensors(self, files):\n",
    "    list_of_tensors = [file_to_tensor(file) for file in files]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Load datasets\n",
    "\n",
    "The function below takes a directory and returns a list of image locations, along with a list of one-hot encoded targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load file locations and labels\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), max(data['target'])+1)\n",
    "    return files, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_image_classification]",
   "language": "python",
   "name": "conda-env-cnn_image_classification-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
